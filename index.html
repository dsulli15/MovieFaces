<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Faces by dsulli15</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Faces</h1>
      <h2 class="project-tagline">Faces is a facial and expression recognition program that can gather sentimental value through small video files. </h2>
      <a href="https://github.com/dsulli15/MovieFaces" class="btn">View on GitHub</a>
      <a href="https://github.com/dsulli15/MovieFaces/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/dsulli15/MovieFaces/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      

<p>ABOUT:</p>

<p>Faces is a facial and sentimental recognition program. Through the input  of small video files, the Faces program is able to grab various images and locate faces, analyze the current facial emotion, and report a sentimental score based on the analyzed expression. </p>

<p>Components:</p>

<p>Faces is built through a Python framework with the assistance of web services. Faces makes use Google Cloud APIs such as Google Vision. Faces also uses the Django Python web framework for maintaining the web services and also an internal database. Faces uses FFmpeg to break down video files into a subfolder of image captures. </p>
<p>
  <img src = "2.png"
         alt = "Python and Django" 
          WIDTH=200 HEIGHT=100/>
  
  <img src = "3.png"
         alt = "FFMPEG" 
       WIDTH=200 HEIGHT=100/>
  <img src = "4.png"
         alt = "Google API" 
       WIDTH=100 HEIGHT=100/>
</p>
      
      
<p>Methodology:</p>

<p>Faces makes use of all its connected components throughout the application. The process of Faces can be broken down into 6 functions. Through the web interface of Faces, the user can upload a video or image file to score. In the case of a video file input, Faces utilizes the FFmpeg framework, and captures images from the video at a predetermined time instance. For the instance of this project, the time is set to every 2 seconds. These image captures are placed into a subfolder to be processed through the Faces application. Faces will cycle through each image and perform the facial recognition process. First, the image will be scanned with the assistance of the Google Vision API for any facial detection. If a face is successfully found, the application will output the sentiment found from the expression. The found sentiment will be recorded and the image will be labeled. The application repeats this process for the remaining images. Once all images have been scanned, Faces will produce an overall sentiment score for the video and will be outputted for the viewing of the user.  </p>
<img src = "Picture1.png"
         alt = "Methodology" />
      
<p>Results:</p>

<p>Overall, the results of this project was highly successful. Faces accomplishes the initial goal that was established for the project. The program can successfully detect a face from inputted video files and can produce an approximate emotion felt by the image. The Google Vision API is a part of Googleâ€™s machine learning and it was able to be observed over the course of the semester that the API would return different sentiments felt for the same picture. This was recognized through various images such as the one seen in the image below.
Over the course of this semester, there would be test runs where the API returned a sentiment value of Joy for this image. The initial hypothesis was that the Vision API saw the teeth from the image and the first sentiment that was associated with this is Joy. We inquired about anyway to inform the API of this problem; however, there was no available option for this. We also found that for a majority of images, the Vision API would return a sentiment of Joy. This was found to be intriguing due to knowing that a certain image was not joyful. Again, we tried to see if there was any way to alter this output, but there was not. Aside from this, the project was found to be successful and it accomplishes its goal. </p>

     <img src = "5.png"
         alt = "Pic 1" 
          WIDTH=400 HEIGHT=300/> 
      <img src = "6.png"
         alt = "Pic 2" 
           WIDTH=400 HEIGHT=300/>
      
      
<p>Conclusion:</p>

<p>Faces initially was exclusive to the Google App Engine API. Due to difficulties, a transition deemed necessary. Through research and trial, the Django framework proved to provide all necessary features. With the use of all components, Faces successfully accomplishes its original objectives and can be carried onward to bigger and better goals. </p>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/dsulli15/MovieFaces">Faces</a> is maintained by <a href="https://github.com/dsulli15">dsulli15</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
